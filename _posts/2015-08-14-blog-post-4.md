---
title: 'Re-Thinking Inverse Graphics With Large Language Models'
date: 04/2024
permalink: /posts/2012/08/ig-llm-egemenkaya/
tags:
  - Inverse Graphics
  - LLMs
  - Spatial Reasoning
---

This is a sample blog post. Lorem ipsum I can't remember the rest of lorem ipsum and don't have an internet connection right now. Testing testing testing this blog post. Blog posts are cool.

Re-Thinking Inverse Graphics With Large Language Models
======

Intro to Inverse Graphics
======

What is Inverse Graphics and why is it important
------
Inverse Graphics (IG) is the process of disentangling an image into physical variables that contain information about its definitive and constituent properties such as its shape, color, material, position, rotation etc. This task is needed to recreate scenes that are otherwise only available as single 2D/3D images. 
The biggest problem with IG is its immerse requirements such as a comprehensive understanding of a 3D environment's spatial and physical properties. This limits their ability to generalize hugely.

How can this limitation be solved?
------
The authors are planning to leverage the proficiency of Large Language Models (LLMs) as LLMs exhibit compositional reasoning abilities that could be beneficial for spatial reasoning in 3D tasks. In order to achieve this, they propose the Inverse-Graphics Large Language Model (IG-LLM). An inverse graphics framework centered around an LLM, that transforms a visual embedding into a structured, compositional 3D-scene representation autoregressively.

What could IG-LLM do?
------
Through the use of an incorporated frozen pre-trained visual encoder and a continuous numeric head to enable end-to-end training, the IG-LLMs could theoretically solve the IG problem through next-token prediction, without needing to use image-space supervision. This research opens up new possibilities to exploit the visual knowledge of LLMs for solving IG problems.
